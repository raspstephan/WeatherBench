{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Notes:\n",
    "- Currently using pandas.cut for binning. Issue with sklearn.preprocessing.KBinsDiscretizer was that bins couldn't be predefined. We need same bins for each batch of y. \n",
    "- basic accuracy pretty bad: 60%.(top_predicted_class=correct_class). Dont know why. Need to recheck loss function, try increasing bins, training data is 2017 only right now.\n",
    "\n",
    "ToDo: change prediction to xarray with each bin as 'member' having value=mid-point of bin. (This was easier with Kbinsdiscretizer since it had an inverse function, now will have to do manually). Then use rmse, crps, rank-histogram evaluation. Not doing right now, since prediction is bad.\n",
    "\n",
    "- Stuff I read:\n",
    "    - too many bins may lead to overfitting (also slow). need to tune.\n",
    "    - high cardinality of data is a problem with OneHot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Questions\n",
    "- should we remove the last 'leaky relu' activation layer? wont make much difference.\n",
    "\n",
    "- should I change the data_generator and load_data fn. directly? currently i made a data_generator_categorical.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from src.data_generator import *\n",
    "from src.data_generator_categorical import *\n",
    "from src.train import *\n",
    "from src.utils import *\n",
    "from src.networks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(0)\n",
    "limit_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = load_args('../nn_configs/B/81.1-resnet_d3_dr_0.1.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['train_years']=['2017']\n",
    "args['valid_years']=['2018']\n",
    "args['test_years']=['2018']\n",
    "args['model_save_dir'] ='/home/garg/data/WeatherBench/predictions/saved_models'\n",
    "args['datadir']='/home/garg/data/WeatherBench/5.625deg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id=args['exp_id']\n",
    "var_dict=args['var_dict']\n",
    "batch_size=args['batch_size']\n",
    "output_vars=args['output_vars']\n",
    "    \n",
    "data_subsample=args['data_subsample']\n",
    "norm_subsample=args['norm_subsample']\n",
    "nt_in=args['nt_in']\n",
    "dt_in=args['dt_in']\n",
    "train_years=args['train_years']\n",
    "valid_years=args['valid_years']\n",
    "test_years=args['test_years']\n",
    "lead_time=args['lead_time']\n",
    "\n",
    "#changing paths\n",
    "model_save_dir=args['model_save_dir']\n",
    "datadir=args['datadir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.merge([xr.open_mfdataset(f'{datadir}/{var}/*.nc', combine='by_coords') for var in var_dict.keys()])\n",
    "mean = xr.open_dataarray(f'{model_save_dir}/{exp_id}_mean.nc') \n",
    "std = xr.open_dataarray(f'{model_save_dir}/{exp_id}_std.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train= ds.sel(time=slice(train_years[0],train_years[-1]))\n",
    "ds_valid= ds.sel(time=slice(valid_years[0],valid_years[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src.data_generator_categorical.DataGenerator"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_generator_categorical import * \n",
    "DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5. , -4.5, -4. , -3.5, -3. , -2.5, -2. , -1.5, -1. , -0.5,  0. ,\n",
       "        0.5,  1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_bins=20\n",
    "bins=np.linspace(-5,5,num_bins+1)\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_train = DataGenerator(\n",
    "            ds_train, var_dict, lead_time, batch_size=batch_size, output_vars=output_vars,\n",
    "            data_subsample=data_subsample, norm_subsample=norm_subsample, nt_in=nt_in, dt_in=dt_in,\n",
    "            mean=mean, std=std, shuffle=True, \n",
    "            is_categorical=True, num_bins=num_bins\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32, 64, 114), (32, 32, 64, 2, 20))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y=dg_train[0]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32, 64, 114), (32, 32, 64, 2, 20))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y=dg_valid[0]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['filters'] = [128, 128, 128, 128, 128, 128, 128, 128, \n",
    "                   128, 128, 128, 128, 128, 128, 128, 128, \n",
    "                   128, 128, 128, 128, num_bins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(filters, kernels, input_shape, bn_position=None, use_bias=True, l2=0,\n",
    "                 skip=True, dropout=0, activation='relu', **kwargs):\n",
    "    x = input = Input(shape=input_shape)\n",
    "\n",
    "    # First conv block to get up to shape\n",
    "    x = convblock(\n",
    "        x, filters[0], kernels[0], bn_position=bn_position, l2=l2, use_bias=use_bias,\n",
    "        dropout=dropout, activation=activation\n",
    "    )\n",
    "\n",
    "    # Resblocks\n",
    "    for f, k in zip(filters[1:-1], kernels[1:-1]):\n",
    "        x = resblock(x, f, k, bn_position=bn_position, l2=l2, use_bias=use_bias,\n",
    "                dropout=dropout, skip=skip, activation=activation)\n",
    "\n",
    "    # Final convolution\n",
    "    output = PeriodicConv2D(\n",
    "        filters[-1], kernels[-1],\n",
    "        conv_kwargs={'kernel_regularizer': regularizers.l2(l2)},\n",
    "    )(x)\n",
    "    output = Activation('linear', dtype='float32')(output)\n",
    "    #output = Activation('linear')(output) \n",
    "    #should we remove linear activation? wont make much diff i think\n",
    "    output1 = Activation('softmax', dtype='float32')(output)\n",
    "    output2 = Activation('softmax', dtype='float32')(output) #for 2 features?\n",
    "    #output= tf.keras.backend.concatenate((output1, output2), axis=-1)\n",
    "    output= tf.keras.backend.stack((output1, output2), axis=3)\n",
    "    return keras.models.Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 64, 114) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d (PeriodicConv2D (None, 32, 64, 128)  715136      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 32, 64, 128)  0           periodic_conv2d[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 64, 128)  512         leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 64, 128)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_1 (PeriodicConv (None, 32, 64, 128)  147584      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 32, 64, 128)  0           periodic_conv2d_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 64, 128)  512         leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 64, 128)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_2 (PeriodicConv (None, 32, 64, 128)  147584      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32, 64, 128)  0           periodic_conv2d_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 64, 128)  512         leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 64, 128)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 64, 128)  0           dropout[0][0]                    \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_3 (PeriodicConv (None, 32, 64, 128)  147584      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 32, 64, 128)  0           periodic_conv2d_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 64, 128)  512         leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 64, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_4 (PeriodicConv (None, 32, 64, 128)  147584      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 32, 64, 128)  0           periodic_conv2d_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 64, 128)  512         leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 64, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 64, 128)  0           add[0][0]                        \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_5 (PeriodicConv (None, 32, 64, 128)  147584      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 32, 64, 128)  0           periodic_conv2d_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 64, 128)  512         leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 64, 128)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_6 (PeriodicConv (None, 32, 64, 128)  147584      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 32, 64, 128)  0           periodic_conv2d_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 64, 128)  512         leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 64, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 64, 128)  0           add_1[0][0]                      \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_7 (PeriodicConv (None, 32, 64, 128)  147584      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 32, 64, 128)  0           periodic_conv2d_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 64, 128)  512         leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 64, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_8 (PeriodicConv (None, 32, 64, 128)  147584      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 32, 64, 128)  0           periodic_conv2d_8[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 64, 128)  512         leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 64, 128)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 64, 128)  0           add_2[0][0]                      \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_9 (PeriodicConv (None, 32, 64, 128)  147584      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 32, 64, 128)  0           periodic_conv2d_9[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 64, 128)  512         leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 64, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_10 (PeriodicCon (None, 32, 64, 128)  147584      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_10[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 64, 128)  0           add_3[0][0]                      \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_11 (PeriodicCon (None, 32, 64, 128)  147584      add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_11[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_12 (PeriodicCon (None, 32, 64, 128)  147584      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_12[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 64, 128)  0           add_4[0][0]                      \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_13 (PeriodicCon (None, 32, 64, 128)  147584      add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_13[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_14 (PeriodicCon (None, 32, 64, 128)  147584      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_14[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 64, 128)  0           add_5[0][0]                      \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_15 (PeriodicCon (None, 32, 64, 128)  147584      add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_15[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_16 (PeriodicCon (None, 32, 64, 128)  147584      dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_16[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 64, 128)  0           add_6[0][0]                      \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_17 (PeriodicCon (None, 32, 64, 128)  147584      add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_17[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_18 (PeriodicCon (None, 32, 64, 128)  147584      dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_18[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 64, 128)  0           add_7[0][0]                      \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_19 (PeriodicCon (None, 32, 64, 128)  147584      add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_19[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_20 (PeriodicCon (None, 32, 64, 128)  147584      dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_20[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 64, 128)  0           add_8[0][0]                      \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_21 (PeriodicCon (None, 32, 64, 128)  147584      add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_21[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_22 (PeriodicCon (None, 32, 64, 128)  147584      dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_22[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 64, 128)  0           add_9[0][0]                      \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_23 (PeriodicCon (None, 32, 64, 128)  147584      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_23[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_24 (PeriodicCon (None, 32, 64, 128)  147584      dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_24[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32, 64, 128)  0           add_10[0][0]                     \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_25 (PeriodicCon (None, 32, 64, 128)  147584      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_25[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_26 (PeriodicCon (None, 32, 64, 128)  147584      dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_26[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 32, 64, 128)  0           add_11[0][0]                     \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_27 (PeriodicCon (None, 32, 64, 128)  147584      add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_27[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_28 (PeriodicCon (None, 32, 64, 128)  147584      dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_28[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 32, 64, 128)  0           add_12[0][0]                     \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_29 (PeriodicCon (None, 32, 64, 128)  147584      add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_29[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_30 (PeriodicCon (None, 32, 64, 128)  147584      dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_30[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 32, 64, 128)  0           add_13[0][0]                     \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_31 (PeriodicCon (None, 32, 64, 128)  147584      add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_31[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_32 (PeriodicCon (None, 32, 64, 128)  147584      dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_32[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 32, 64, 128)  0           add_14[0][0]                     \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_33 (PeriodicCon (None, 32, 64, 128)  147584      add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_33[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_34 (PeriodicCon (None, 32, 64, 128)  147584      dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_34[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 32, 64, 128)  0           add_15[0][0]                     \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_35 (PeriodicCon (None, 32, 64, 128)  147584      add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_35[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_36 (PeriodicCon (None, 32, 64, 128)  147584      dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_36[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 32, 64, 128)  0           add_16[0][0]                     \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_37 (PeriodicCon (None, 32, 64, 128)  147584      add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_37[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_38 (PeriodicCon (None, 32, 64, 128)  147584      dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_38[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 32, 64, 128)  0           add_17[0][0]                     \n",
      "                                                                 dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_39 (PeriodicCon (None, 32, 64, 20)   23060       add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 64, 20)   0           periodic_conv2d_39[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 64, 20)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 64, 20)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack (TensorFlowOp [(None, 32, 64, 2, 2 0           activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,366,356\n",
      "Trainable params: 6,356,372\n",
      "Non-trainable params: 9,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_resnet(\n",
    "    **args, input_shape=dg_train.shape,\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo: Solve assert issue. make it general for len(output_vars)\n",
    "def custom_categorical_loss(y_true, y_pred):\n",
    "    #assert tf.shape(y_true)==tf.shape(y_pred)\n",
    "    #assert tf.rank(y_true)==5 #[batch_size, lat, lon, 2, ]\n",
    "    #assert tf.shape(y_true)[3]==2 #len(args['outpt_vars'])\n",
    "    \n",
    "    cce=tf.keras.losses.CategoricalCrossentropy()\n",
    "    cce1=cce(y_true[:,:,:,0,:], y_pred[:,:,:,0,:])\n",
    "    cce2=cce(y_true[:,:,:,1,:], y_pred[:,:,:,1,:])\n",
    "    return (cce1+cce2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adam'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args['optimizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(keras.optimizers.Adam(1e-3), custom_categorical_loss) \n",
    "#accuracy metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 136 steps\n",
      "Epoch 1/10\n",
      "136/136 [==============================] - 68s 501ms/step - loss: 5.3725\n",
      "Epoch 2/10\n",
      "136/136 [==============================] - 60s 440ms/step - loss: 2.6342\n",
      "Epoch 3/10\n",
      "136/136 [==============================] - 60s 441ms/step - loss: 2.0872\n",
      "Epoch 4/10\n",
      "136/136 [==============================] - 60s 440ms/step - loss: 1.9290\n",
      "Epoch 5/10\n",
      "136/136 [==============================] - 60s 440ms/step - loss: 1.8309\n",
      "Epoch 6/10\n",
      "136/136 [==============================] - 60s 440ms/step - loss: 1.7763\n",
      "Epoch 7/10\n",
      "136/136 [==============================] - 60s 440ms/step - loss: 1.7255\n",
      "Epoch 8/10\n",
      "136/136 [==============================] - 60s 440ms/step - loss: 1.6965\n",
      "Epoch 9/10\n",
      "136/136 [==============================] - 60s 440ms/step - loss: 1.6541\n",
      "Epoch 10/10\n",
      "136/136 [==============================] - 60s 441ms/step - loss: 1.6367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1bc4216bd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dg_train, epochs=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/garg/miniconda3/envs/weatherbench/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /home/garg/data/WeatherBench/predictions/saved_models/categorical_v1/assets\n"
     ]
    }
   ],
   "source": [
    "model_save_dir\n",
    "model.save(f'{model_save_dir}/categorical_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation:\n",
    "for a basic evaluation, using y as a onehot vector. ideally would not change y but change prediction values to mid-points of each bin. and call each bin as a 'member'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_valid = DataGenerator(\n",
    "            ds_valid, var_dict, lead_time, batch_size=batch_size,\n",
    "            data_subsample=data_subsample,\n",
    "            mean=dg_train.mean, std=dg_train.std,shuffle=False, \n",
    "            output_vars=output_vars, nt_in=nt_in, \n",
    "            dt_in=dt_in, is_categorical=True, num_bins=num_bins\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.data_generator_categorical.DataGenerator at 0x7f1b4f28c210>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict(dg_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4342, 32, 64, 2, 20)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=dg_valid[0]\n",
    "pred=model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32, 64, 2, 20), (32, 32, 64, 2, 20))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.max(), y.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class=pred.argmax(axis=4)\n",
    "truth_class=y.argmax(axis=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32, 64, 2), (32, 32, 64, 2))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class.shape, truth_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (predicted_class == truth_class).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5965118408203125"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy #pretty bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Testing. Ignore all below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "#import keras_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = load_args('../nn_configs/B/81.1-resnet_d3_dr_0.1.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['model_save_dir'] ='/home/garg/data/WeatherBench/predictions/saved_models'\n",
    "args['datadir']='/home/garg/data/WeatherBench/5.625deg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#args['train_years'] = ['2017']\n",
    "#dg_train, dg_valid, dg_test = load_data(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args['var_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['var_dict']={'geopotential': ('z', [50, 250, 500, 600, 700, 850, 925]),\n",
    " 'temperature': ('t', [50, 250, 500, 600, 700, 850, 925]),\n",
    " 'u_component_of_wind': ('u', [50, 250, 500, 600, 700, 850, 925]),\n",
    " 'v_component_of_wind': ('v', [50, 250, 500, 600, 700, 850, 925]),\n",
    " 'constants': ['lsm', 'orography', 'lat2d']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict=args['var_dict']; datadir=args['datadir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['train_years']=['2017']\n",
    "args['valid_years']=['2018']\n",
    "args['test_years']=['2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_train, dg_valid, dg_test = load_data(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dg_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.6023862, -3.7825012)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.max(), y.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y =dg_train[0]\n",
    "for i in range(30):\n",
    "    X_batch,y_batch=dg_train[i+1]\n",
    "    X=np.append(X,X_batch,axis=0)\n",
    "    y=np.append(y,y_batch,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((992, 32, 64, 93), (992, 32, 64, 2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4063232, 1)\n",
      "(4063232, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#z=y[:,:,:,0] #Single feature\n",
    "z=y #both features.\n",
    "z=z.reshape(-1,1)\n",
    "#z=z.reshape(y.shape[0],-1)\n",
    "print(z.shape)\n",
    "\n",
    "discretizer = KBinsDiscretizer(n_bins=n_bins, encode='onehot', \n",
    "                               strategy='quantile') #may change to uniform\n",
    "\n",
    "zbinned=discretizer.fit_transform(z)\n",
    "print(zbinned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4063232x10 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4063232 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zbinned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4063232, 10)\n"
     ]
    }
   ],
   "source": [
    "zbinned=zbinned.toarray(); print(zbinned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(992, 32, 64, 2, 10)\n"
     ]
    }
   ],
   "source": [
    "#zbinned=zbinned.reshape(y.shape[0],y.shape[1],y.shape[2],2*n_bins)#both features\n",
    "zbinned=zbinned.reshape(y.shape[0],y.shape[1],y.shape[2],2, n_bins)#both features\n",
    "#zbinned=zbinned.reshape(y.shape[0],y.shape[1],y.shape[2],n_bins)#single feature\n",
    "\n",
    "print(zbinned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zbinned.min(), zbinned.max(), zbinned.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maybe we should always keep features normalized before binning. so bin edges are similar proportioned in all dimensions\n",
    "#dont know how quantiles will work when loading data in batches. bin edges should be same for each batch.\n",
    "#should we have different edges for each feature.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " array([array([-3.78250122, -1.52675844, -1.00765502, -0.56459385, -0.14745411,\n",
       "         0.27951834,  0.69605088,  1.01107681,  1.11988294,  1.19609022,\n",
       "         2.60238624])], dtype=object))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discretizer.n_bins, discretizer.bin_edges_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.7825012, 2.6023862)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.min(), z.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse=discretizer.inverse_transform(zbinned)\n",
    "# inverse, print((-3.70667171 + -1.57529008)/2) #middle point of each bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Another Method\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import tensorflow.keras.utils\n",
    "\n",
    "# y.shape\n",
    "# encoder=LabelEncoder()\n",
    "# z=y.reshape(-1,1)\n",
    "\n",
    "\n",
    "# encoder.fit(z)\n",
    "# encoded_Y = encoder.transform(z)\n",
    "# # convert integers to dummy variables (i.e. one hot encoded)\n",
    "# dummy_y = tensorflow.keras.utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another method to convert from integer labels (1,2..10) to onehot.\n",
    "#y_train = np_utils.to_categorical(y=y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input done. ToDo: make same bin sizes for each batch of input data.\n",
    "#Now change model last layer. Add softmax (not sigmoid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "a=np.zeros((5,4,3,2))\n",
    "b=np.zeros((5,4,3,2))\n",
    "c=np.concatenate((a,b), axis=-1)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=np.stack((a,b), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4, 3, 2, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(filters, kernels, input_shape, bn_position=None, use_bias=True, l2=0,\n",
    "                 skip=True, dropout=0, activation='relu', **kwargs):\n",
    "    x = input = Input(shape=input_shape)\n",
    "\n",
    "    # First conv block to get up to shape\n",
    "    x = convblock(\n",
    "        x, filters[0], kernels[0], bn_position=bn_position, l2=l2, use_bias=use_bias,\n",
    "        dropout=dropout, activation=activation\n",
    "    )\n",
    "\n",
    "    # Resblocks\n",
    "    for f, k in zip(filters[1:-1], kernels[1:-1]):\n",
    "        x = resblock(x, f, k, bn_position=bn_position, l2=l2, use_bias=use_bias,\n",
    "                dropout=dropout, skip=skip, activation=activation)\n",
    "\n",
    "    # Final convolution\n",
    "    output = PeriodicConv2D(\n",
    "        filters[-1], kernels[-1],\n",
    "        conv_kwargs={'kernel_regularizer': regularizers.l2(l2)},\n",
    "    )(x)\n",
    "    output = Activation('linear', dtype='float32')(output)\n",
    "    #output = Activation('linear')(output) \n",
    "    #should we remove linear activation? wont make much diff i think\n",
    "    output1 = Activation('softmax', dtype='float32')(output)\n",
    "    output2 = Activation('softmax', dtype='float32')(output) #for 2 features?\n",
    "    #output= tf.keras.backend.concatenate((output1, output2), axis=-1)\n",
    "    output= tf.keras.backend.stack((output1, output2), axis=3)\n",
    "    return keras.models.Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['filters'] = [128, 128, 128, 128, 128, 128, 128, 128, \n",
    "                   128, 128, 128, 128, 128, 128, 128, 128, \n",
    "                   128, 128, 128, 128, n_bins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 64, 93)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d (PeriodicConv2D (None, 32, 64, 128)  583424      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 32, 64, 128)  0           periodic_conv2d[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 64, 128)  512         leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 64, 128)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_1 (PeriodicConv (None, 32, 64, 128)  147584      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 32, 64, 128)  0           periodic_conv2d_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 64, 128)  512         leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 64, 128)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_2 (PeriodicConv (None, 32, 64, 128)  147584      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32, 64, 128)  0           periodic_conv2d_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 64, 128)  512         leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 64, 128)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 64, 128)  0           dropout[0][0]                    \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_3 (PeriodicConv (None, 32, 64, 128)  147584      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 32, 64, 128)  0           periodic_conv2d_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 64, 128)  512         leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 64, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_4 (PeriodicConv (None, 32, 64, 128)  147584      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 32, 64, 128)  0           periodic_conv2d_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 64, 128)  512         leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 64, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 64, 128)  0           add[0][0]                        \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_5 (PeriodicConv (None, 32, 64, 128)  147584      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 32, 64, 128)  0           periodic_conv2d_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 64, 128)  512         leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 64, 128)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_6 (PeriodicConv (None, 32, 64, 128)  147584      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 32, 64, 128)  0           periodic_conv2d_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 64, 128)  512         leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 64, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 64, 128)  0           add_1[0][0]                      \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_7 (PeriodicConv (None, 32, 64, 128)  147584      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 32, 64, 128)  0           periodic_conv2d_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 64, 128)  512         leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 64, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_8 (PeriodicConv (None, 32, 64, 128)  147584      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 32, 64, 128)  0           periodic_conv2d_8[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 64, 128)  512         leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 64, 128)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 64, 128)  0           add_2[0][0]                      \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_9 (PeriodicConv (None, 32, 64, 128)  147584      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 32, 64, 128)  0           periodic_conv2d_9[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 64, 128)  512         leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 64, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_10 (PeriodicCon (None, 32, 64, 128)  147584      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_10[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 64, 128)  0           add_3[0][0]                      \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_11 (PeriodicCon (None, 32, 64, 128)  147584      add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_11[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_12 (PeriodicCon (None, 32, 64, 128)  147584      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_12[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 64, 128)  0           add_4[0][0]                      \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_13 (PeriodicCon (None, 32, 64, 128)  147584      add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_13[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_14 (PeriodicCon (None, 32, 64, 128)  147584      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_14[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 64, 128)  0           add_5[0][0]                      \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_15 (PeriodicCon (None, 32, 64, 128)  147584      add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_15[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_16 (PeriodicCon (None, 32, 64, 128)  147584      dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_16[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 64, 128)  0           add_6[0][0]                      \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_17 (PeriodicCon (None, 32, 64, 128)  147584      add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_17[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_18 (PeriodicCon (None, 32, 64, 128)  147584      dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_18[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 64, 128)  0           add_7[0][0]                      \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_19 (PeriodicCon (None, 32, 64, 128)  147584      add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_19[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_20 (PeriodicCon (None, 32, 64, 128)  147584      dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_20[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 64, 128)  0           add_8[0][0]                      \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_21 (PeriodicCon (None, 32, 64, 128)  147584      add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_21[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_22 (PeriodicCon (None, 32, 64, 128)  147584      dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_22[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 64, 128)  0           add_9[0][0]                      \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_23 (PeriodicCon (None, 32, 64, 128)  147584      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_23[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_24 (PeriodicCon (None, 32, 64, 128)  147584      dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_24[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32, 64, 128)  0           add_10[0][0]                     \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_25 (PeriodicCon (None, 32, 64, 128)  147584      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_25[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_26 (PeriodicCon (None, 32, 64, 128)  147584      dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_26[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 32, 64, 128)  0           add_11[0][0]                     \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_27 (PeriodicCon (None, 32, 64, 128)  147584      add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_27[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_28 (PeriodicCon (None, 32, 64, 128)  147584      dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_28[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 32, 64, 128)  0           add_12[0][0]                     \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_29 (PeriodicCon (None, 32, 64, 128)  147584      add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_29[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_30 (PeriodicCon (None, 32, 64, 128)  147584      dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_30[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 32, 64, 128)  0           add_13[0][0]                     \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_31 (PeriodicCon (None, 32, 64, 128)  147584      add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_31[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_32 (PeriodicCon (None, 32, 64, 128)  147584      dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_32[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 32, 64, 128)  0           add_14[0][0]                     \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_33 (PeriodicCon (None, 32, 64, 128)  147584      add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_33[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_34 (PeriodicCon (None, 32, 64, 128)  147584      dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_34[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 32, 64, 128)  0           add_15[0][0]                     \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_35 (PeriodicCon (None, 32, 64, 128)  147584      add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_35[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_36 (PeriodicCon (None, 32, 64, 128)  147584      dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_36[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 32, 64, 128)  0           add_16[0][0]                     \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_37 (PeriodicCon (None, 32, 64, 128)  147584      add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_37[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_38 (PeriodicCon (None, 32, 64, 128)  147584      dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, 32, 64, 128)  0           periodic_conv2d_38[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 32, 64, 128)  512         leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 32, 64, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 32, 64, 128)  0           add_17[0][0]                     \n",
      "                                                                 dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_39 (PeriodicCon (None, 32, 64, 10)   11530       add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 64, 10)   0           periodic_conv2d_39[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 64, 10)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 64, 10)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack (TensorFlowOp [(None, 32, 64, 2, 1 0           activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,223,114\n",
      "Trainable params: 6,213,130\n",
      "Non-trainable params: 9,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = build_resnet(\n",
    "    **args, input_shape=dg_train.shape,\n",
    ")\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.float32, TensorShape([2, 32, 64, 2, 10]))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model2(X[0:2])\n",
    "pred.dtype, pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=12194, shape=(), dtype=float32, numpy=0.0>,\n",
       " <tf.Tensor: id=12196, shape=(), dtype=float32, numpy=1.0>,\n",
       " <tf.Tensor: id=12198, shape=(), dtype=float32, numpy=0.1>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(pred), tf.reduce_max(pred), tf.reduce_mean(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[8.1115775e-03 3.1604444e-19 1.2055289e-33 9.9101175e-22 1.6745210e-27\n",
      " 2.5492799e-35 9.9188846e-01 4.5411613e-31 0.0000000e+00 2.5258964e-10], shape=(10,), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(pred[0,0,0,0,:]) \n",
    "print(tf.reduce_sum(pred[0,0,0,0,0:10]))\n",
    "print(tf.reduce_sum(pred[0,0,0,1,0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Fn.\n",
    "categorical_loss=tf.keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=zbinned[0:2,...]\n",
    "y_pred=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_true=tf.convert_to_tensor(zbinned.toarray(), dtype='float32')\n",
    "#y_pred=tf.reshape(pred, shape=(y_true.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 32, 64, 2, 10),\n",
       " TensorShape([2, 32, 64, 2, 10]),\n",
       " <tf.Tensor: id=14107, shape=(), dtype=float64, numpy=0.1>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape, y_pred.shape, tf.reduce_mean(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 32, 64, 2, 10]),\n",
       " <tf.Tensor: id=14109, shape=(), dtype=float32, numpy=0.1>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape, tf.reduce_mean(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce1=categorical_loss(y_true, y_pred)\n",
    "cce2=categorical_loss(y_true[:,:,:,0,:], y_pred[:,:,:,0,:])+categorical_loss(y_true[:,:,:,1,:], y_pred[:,:,:,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=14142, shape=(), dtype=float32, numpy=14.252204>,\n",
       " <tf.Tensor: id=14217, shape=(), dtype=float32, numpy=28.504414>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cce1, cce2 #need to ensure if this is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 32, 64, 20), TensorShape([2, 32, 64, 20]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true3=y_true.reshape(y_true.shape[0], y_true.shape[1], y_true.shape[2], 2*y_true.shape[4])\n",
    "pred3=tf.reshape(pred, (pred.shape[0], pred.shape[1], pred.shape[2], 2*pred.shape[4]))\n",
    "y_true2.shape, pred2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=14252, shape=(), dtype=float32, numpy=28.726276>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cce3=categorical_loss(y_true3, pred3)\n",
    "cce3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4096, 20), TensorShape([4096, 20]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true4=y_true.reshape(-1, 2*y_true.shape[4])\n",
    "pred4=tf.reshape(pred, (-1, 2*pred.shape[4]))\n",
    "y_true4.shape, pred4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=14287, shape=(), dtype=float32, numpy=28.726276>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cce4=categorical_loss(y_true4, pred4)\n",
    "cce4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 32, 64, 2, 10)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true5_1=y_true[:,:,:,0,:].reshape(-1, n_bins)\n",
    "y_true5_2=y_true[:,:,:,1,:].reshape(-1, n_bins)\n",
    "\n",
    "\n",
    "pred5_1=tf.reshape(pred[:,:,:,0,:],(-1, n_bins))\n",
    "pred5_2=tf.reshape(pred[:,:,:,1,:],(-1, n_bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4096, 10), TensorShape([4096, 10]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true5_1.shape, pred5_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=14366, shape=(), dtype=float32, numpy=28.504414>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cce5=categorical_loss(y_true5_1, pred5_1)+categorical_loss(y_true5_2, pred5_2)\n",
    "cce5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(14.252204, shape=(), dtype=float32) \n",
      " tf.Tensor(28.504414, shape=(), dtype=float32) \n",
      " tf.Tensor(28.726276, shape=(), dtype=float32) \n",
      " tf.Tensor(28.726276, shape=(), dtype=float32) \n",
      " tf.Tensor(28.504414, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(cce1, '\\n', cce2, '\\n',cce3, '\\n',cce4, '\\n',cce5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so it matters if its [..., 2, 10] or [..., 20] but doesnt matter if [2,32,64,...] or [4096, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_pred.ndim==5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "perdasds=tf.reshape(y_pred[:,:,:,0,:], (-1, y_pred.shape[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 32, 64, 10])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:,:,:,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(args['output_vars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=15847, shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(pred)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_categorical_loss(y_true, y_pred):\n",
    "    #assert tf.shape(y_true)==tf.shape(y_pred)\n",
    "    #assert tf.rank(y_true)==5 #[batch_size, lat, lon, 2, ]\n",
    "    #assert tf.shape(y_true)[3]==2 #len(args['outpt_vars'])\n",
    "    \n",
    "    cce=tf.keras.losses.CategoricalCrossentropy()\n",
    "    cce1=cce(y_true[:,:,:,0,:], y_pred[:,:,:,0,:])\n",
    "    cce2=cce(y_true[:,:,:,1,:], y_pred[:,:,:,1,:])\n",
    "    return (cce1+cce2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adam'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args['optimizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(keras.optimizers.Adam(1e-3), custom_categorical_loss) #metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(992, 32, 64, 2, 10)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true=zbinned\n",
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 992 samples\n",
      "Epoch 1/10\n",
      "992/992 [==============================] - 20s 20ms/sample - loss: 14.4971\n",
      "Epoch 2/10\n",
      "992/992 [==============================] - 12s 12ms/sample - loss: 7.1829\n",
      "Epoch 3/10\n",
      "992/992 [==============================] - 12s 12ms/sample - loss: 3.2941\n",
      "Epoch 4/10\n",
      "992/992 [==============================] - 12s 12ms/sample - loss: 2.9438\n",
      "Epoch 5/10\n",
      "992/992 [==============================] - 12s 12ms/sample - loss: 2.7901\n",
      "Epoch 6/10\n",
      "992/992 [==============================] - 12s 12ms/sample - loss: 2.9497\n",
      "Epoch 7/10\n",
      "992/992 [==============================] - 13s 13ms/sample - loss: 2.8081\n",
      "Epoch 8/10\n",
      "992/992 [==============================] - 13s 13ms/sample - loss: 2.6714\n",
      "Epoch 9/10\n",
      "992/992 [==============================] - 13s 13ms/sample - loss: 2.5916\n",
      "Epoch 10/10\n",
      "992/992 [==============================] - 13s 13ms/sample - loss: 2.5506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff9752a1550>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X, y_true, \n",
    "          batch_size=32, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(992, 32, 64, 2, 10)\n",
      "pred:\n",
      "tf.Tensor(0.074389875, shape=(), dtype=float32)\n",
      "tf.Tensor(0.098409444, shape=(), dtype=float32)\n",
      "tf.Tensor(0.107323214, shape=(), dtype=float32)\n",
      "tf.Tensor(0.094795525, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10606819, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1469336, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13323091, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13979475, shape=(), dtype=float32)\n",
      "tf.Tensor(0.062539145, shape=(), dtype=float32)\n",
      "tf.Tensor(0.03651534, shape=(), dtype=float32)\n",
      "\n",
      " truth:\n",
      "tf.Tensor(0.09998887585055444, shape=(), dtype=float64)\n",
      "tf.Tensor(0.09991135135773689, shape=(), dtype=float64)\n",
      "tf.Tensor(0.10008141302293347, shape=(), dtype=float64)\n",
      "tf.Tensor(0.09999675135458669, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0999539283014113, shape=(), dtype=float64)\n",
      "tf.Tensor(0.09996697210496472, shape=(), dtype=float64)\n",
      "tf.Tensor(0.10007501417590726, shape=(), dtype=float64)\n",
      "tf.Tensor(0.09956556750882056, shape=(), dtype=float64)\n",
      "tf.Tensor(0.10016189082976311, shape=(), dtype=float64)\n",
      "tf.Tensor(0.10029823549332158, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(pred.shape)\n",
    "print(\"pred:\")\n",
    "for i in range(10):\n",
    "    print(tf.reduce_mean(pred[...,i]))\n",
    "print (\"\\n truth:\")\n",
    "for i in range(10):\n",
    "    print(tf.reduce_mean(y_true[...,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([-3.78250122, -1.52675844, -1.00765502, -0.56459385, -0.14745411,\n",
       "        0.27951834,  0.69605088,  1.01107681,  1.11988294,  1.19609022,\n",
       "        2.60238624])], dtype=object)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discretizer.bin_edges_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4063232, 10)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plotting\n",
    "pred.shape; pred1=pred.reshape(-1,10); pred1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=34533, shape=(10,), dtype=float32, numpy=\n",
       "array([0.0743898 , 0.09840944, 0.1073232 , 0.09479552, 0.10606818,\n",
       "       0.14693357, 0.13323088, 0.1397947 , 0.06253915, 0.03651533],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mean=tf.reduce_mean(pred1,axis=0)\n",
    "\n",
    "pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff864c6efd0>]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pred_mean) \n",
    "#should ideally be a flat line since we are doing binning by quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff864b30650>,\n",
       " <matplotlib.lines.Line2D at 0x7ff864b30850>]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAZhElEQVR4nO3de5RU1Z328e+PRhTUgEAHlEaRBC+sxBjtEKND5JXEgPMmaMxMkEQSxGHIiKIxAmq8C44QiRdQRATCMooshxjekXgZJRk1Y4ZmEi8IJO2VlqCNFyQil+7+vX/sZmjavlRDVe+qXc9nrV5Q55yuelKRp0/vOmdvc3dERKTwdYgdQEREskOFLiKSCBW6iEgiVOgiIolQoYuIJKJjrBfu2bOn9+vXL9bLi4gUpFWrVm1y99Km9kUr9H79+lFRURHr5UVECpKZvdHcPg25iIgkQoUuIpIIFbqISCJU6CIiiVChi4gkotVCN7P5ZvaOmb3UzH4zs9vNrNLMXjCzE7IfM3/07g1mn/zq3Tt2MhEpdpmcoS8EhrWwfzgwoP5rHHDXvsfKX2+/3bbtIiLtpdVCd/f/BN5r4ZARwCIPngO6mdmh2QooIiKZycYYeh9gfYPHVfXbPsHMxplZhZlVVFdXZ+GlRURkl2wUujWxrclVM9x9rruXu3t5aWmTd66KiMheykahVwF9GzwuAzZk4XlFRKQNslHoy4DR9Ve7nARsdve/ZuF581KvXm3bLiLSXlqdnMvMHgCGAD3NrAq4BtgPwN3nAMuBM4BKYCswJldh88HGjbETiIg0rdVCd/dzWtnvwAVZSyQiIntFd4qKiCRChS4ikggVuohIIlToIiKJUKGLiCRChS4ikggVuohIIlToIiKJUKGLiCRChS4ikggVuohIIlToIiKJUKGLiCRChS4ikggVuohIIlToIiKJUKGLiCRChS4ikggVuohIIlToIiKJUKGLiCRChS4ikggVuohIIlToIiKJUKGLiCRChS4ikggVuohIIlToIiKJUKGLiCRChS4ikggVuohIIjIqdDMbZmbrzKzSzKY0sb+rmf0/M3vezFab2ZjsRxURkZa0WuhmVgLMBoYDA4FzzGxgo8MuAF529y8AQ4BbzKxTlrOKiEgLMjlDHwRUuvur7r4DWAyMaHSMAwebmQEHAe8BNVlNKiIiLcqk0PsA6xs8rqrf1tAs4FhgA/AiMNHd6xo/kZmNM7MKM6uorq7ey8giItKUTArdmtjmjR5/A/gTcBhwPDDLzD71iW9yn+vu5e5eXlpa2uawIiLSvEwKvQro2+BxGeFMvKExwFIPKoHXgGOyE1FERDKRSaGvBAaY2ZH1H3SOBJY1OuZNYCiAmfUCjgZezWZQERFpWcfWDnD3GjObADwGlADz3X21mY2v3z8HuAFYaGYvEoZoJrv7phzmFhGRRlotdAB3Xw4sb7RtToO/bwBOz240ERFpC90pKiKSCBW6iEgiVOgiIolQoYuIJEKFLiKSCBW6iEgiVOgiIolQoYuIJEKFLiKSCBW6iEgiVOgiIolQoYuIJEKFLiKSCBW6iEgiVOgiIolQoYuIJEKFLiKSCBW6iEgiVOgiIolQoYuIJEKFLiKSCBW6iEgiVOgiIolQoYuIJEKFLiKSCBW6iEgiVOgiIolQoYuIJEKFLiKSCBW6iEgiMip0MxtmZuvMrNLMpjRzzBAz+5OZrTaz32U3poiItKZjaweYWQkwG/g6UAWsNLNl7v5yg2O6AXcCw9z9TTP7dK4Ci4hI0zI5Qx8EVLr7q+6+A1gMjGh0zChgqbu/CeDu72Q3poiItCaTQu8DrG/wuKp+W0NHAYeY2W/NbJWZjW7qicxsnJlVmFlFdXX13iUWEZEmZVLo1sQ2b/S4I3Ai8PfAN4CrzOyoT3yT+1x3L3f38tLS0jaHFRGR5rU6hk44I+/b4HEZsKGJYza5+0fAR2b2n8AXgD9nJaWIiLQqkzP0lcAAMzvSzDoBI4FljY75NTDYzDqaWRfgy8Ca7EYVEZGWtHqG7u41ZjYBeAwoAea7+2ozG1+/f467rzGzR4EXgDpgnru/lMvgIiKyJ3NvPBzePsrLy72ioiLKa4uIFCozW+Xu5U3t052iIiKJUKGLiCRChS4ikggVuohIIlToIiKJUKGLiCRChS4ikggVuohIIlToIiKJUKGLiCRChS4ikggVuohIIlToIiKJUKGLiCRChS4ikggVuohIIlToIiKJUKGLiCRChV7onnoKliyJnUJE8kCri0RLHtu0Cc4+Gz74AKqr4YILYicSkYh0hl7IrrkGtmyBIUNgwgSYPz92IhGJSIVeqF58EebMgR/9CB59FL7xDTj/fHjggdjJRCQSFXohcodLLoFu3eC662D//WHpUjj1VDj3XPjVr2InFJEIVOiFaNkyePLJUObdu4dtXbqE7YMGwXe/G87aRaSoqNALzfbtcOmlMHAgjB+/576DD4bly+Hzn4ezzoIVK+JkFJEoVOiF5rbb4JVX4NZboWMTFyl16waPPQaf+Qx885vw+9+3f0YRiUKFXkg2boQbbghF/fWvN39cz57wH/8Bhx0Gw4fDqlXtl1FEolGhF5IrrwxDLrfc0vqxvXuHcfbu3eH008NVMSKSNBV6oVi1ChYsgIkTYcCAzL6nb99Q6p07hzP6detym1FEolKhFwL3UOSlpfDTn7bte/v3D6XuDkOHwmuv5SajiESnQi8EDz4Izz4LU6dC165t//6jj4YnnoCPP4bTToOqquxnFJHoMip0MxtmZuvMrNLMprRw3JfMrNbMvpO9iEVu61aYNAm++EUYM2bvn+e448LVL++9F87UN27MXkYRyQutFrqZlQCzgeHAQOAcMxvYzHE3A49lO2RRmzED1q8PlyuWlOzbc5WXw29+A2+9FcbUN23KTkYRyQuZnKEPAird/VV33wEsBkY0cdyFwL8B72QxX3Fbvx5uvhn+8R9h8ODsPOfJJ4c7Sisrw/wvH3yQnecVkegyKfQ+wPoGj6vqt/0vM+sDnAXMaemJzGycmVWYWUV1dXVbsxafyZPDh5nTp2f3eU87Lcz98uKLcMYZ8Le/Zff5RSSKTArdmtjmjR7fCkx299qWnsjd57p7ubuXl5aWZpqxOD37bJg58bLL4Igjsv/8w4fD4sXw3/8dblT6+OPsv4aItKtMCr0K6NvgcRmwodEx5cBiM3sd+A5wp5mdmZWExaiuLlym2KdPOEvPlW9/GxYtgt/9Lvx9+/bcvZaI5FwmKxatBAaY2ZHAW8BIYFTDA9z9yF1/N7OFwL+7+8NZzFlcFi0KNxLddx8ceGBuX2vUKNi2DcaOhZEjw3J2++2X29cUkZxo9Qzd3WuACYSrV9YAS9x9tZmNN7PxLX+3tNmWLXD55XDSSaFs28N558Edd8DDD8Po0VDb4siZiOSpjNYUdfflwPJG25r8ANTdf7jvsYrYtGnhGvFf/xqsqY8vcmTChHDN++TJYaqAefOgg+47EykkWiQ6n7zyCsycGc6SBw1q/9efNCmU+nXXhQUz7rijfX+oiMg+UaHnk8suC+PXN90UL8M114RSnzEjnKlPn65SFykQKvR88dRTYS3QqVPDPOaxmIWbmbZuhZ/9LHwoe+218fKISMZU6PmgpgYuvhj69YMf/zh2mlDqt9++e/ilc+fcXj4pIlmhQs8H8+aFuzYfeggOOCB2mqBDB7jnnnDD0ZQpYUz9wgtjpxKRFqjQY3v//TDH+amnhpt78klJSbgmfts2uOiiUOpjx8ZOJSLN0HVpsV1/fSj1W2/Nzw8f99svTBEwbBj80z/B/ffHTiQizVChx7R2LcyaBeefD8cfHztN8/bfP0zmNWRIuKRy6dLYiUSkCSr0mH7843AVyY03xk7Sus6dw7S7gwaFKQKWL2/9e0SkXanQY1m+PCw2cfXVYa3QQnDQQSH35z8fxvuffDJ2IhFpQIUew44d4ez8qKPCLfeFpFs3ePxxGDAAvvWtMM2viOQFFXoMs2fDunXhNv9OnWKnabsePcKi02VlYV71iorYiUQEFXr7q64ON+sMGxZWCypUvXuHIZcePeD00+GFF2InEil6KvT2dtVVYcm3mTPz8zLFtigrC6XepUtYdHrt2tiJRIqaCr09Pf98uPvyggvg2GNjp8mO/v13fzh69tla9UgkIhV6e3EP87Ucckh6k10dfTQsXAgvvxxmaxSRKFTo7eVXv4Lf/jbcGXrIIbHTZN/w4WFagBkz4LnnYqcRKUrm7lFeuLy83CuK5eqIbdvCEMtBB8Ef/wgdE51CZ/PmcI16ly7hf2fnzrETiSTHzFa5e3lT+3SG3h5+/nN4/fUwX0uqZQ7QtSvMnx8uyfzpT2OnESk6KvRc27AhLFpx5pkwdGjsNLn3ta/Bj34Ufog9/XTsNCJFRYWea1dcATt3htV/isX06WGxjjFj4KOPYqcRKRoq9FxauRJ+8Qu45BL4zGdip2k/Bx0ECxaERa+nTImdRqRoqNBzxR0mToReveDKK2OnaX+nnhoWxZg1C1asiJ1GpCio0HPlgQfgv/4LbroJDj44dpo4broJPvtZOO882LIldhqR5KnQc+Gjj2DSJDjxRPjBD2KniadLl3DD0RtvwGWXxU4jkjwVei5Mnw5vvQW33RYWWy5mp5wCl14Kd98dpt0VkZwp8rbJgTfeCIU+cmQoMwl3xx5zTLiTdPPm2GlEkqVCz7bJk8MsijffHDtJ/ujcOVzts2FDuOJHRHJChZ5NTz8NDz4Yxs8PPzx2mvwyaFD4YbdgATzySOw0IknSXC7ZUlsLX/pSWMBi3brwgaDsaft2KC+Hd9+Fl16C7t1jJxIpOPs8l4uZDTOzdWZWaWafuFPEzL5nZi/Uf/3ezL6wr6ELzsKFYUKq6dNV5s3Zf/8w9FJdHa7RF5GsarXQzawEmA0MBwYC55jZwEaHvQac6u7HATcAc7MdNK99+GG4xf/kk8OHodK8E04IN1rddx88/HDsNCJJyeQMfRBQ6e6vuvsOYDEwouEB7v57d3+//uFzQFl2Y+a5G2+Ed94JlykW+rJy7eGKK+D44+Gf/xk2bYqdRiQZmRR6H2B9g8dV9duaMxb4TVM7zGycmVWYWUV1dXXmKfPZX/4SpsX94Q/D+LC0rlOnMPTy/vthOT4RyYpMCr2pU84mP0k1s/9DKPTJTe1397nuXu7u5aWlpZmnzGc/+UkYG542LXaSwnLccWG5uiVLwpeI7LNMCr0K6NvgcRmwofFBZnYcMA8Y4e7vZidennviCVi2LIwJH3po7DSFZ/Lk8FvNv/wLvP127DQiBS+TQl8JDDCzI82sEzASWNbwADM7HFgKnOvuf85+zDxUUxNukunfPyz+LG3XsWMYevnb38KiGJEuoRVJRauF7u41wATgMWANsMTdV5vZeDMbX3/Y1UAP4E4z+5OZJXSBeTOmTYPVq8PCFQccEDtN4Ro4EG64ISyiff/9sdOIFDTdWLQ3bropXKkxalS4/E5Xtuyb2loYPBjWrg03HB12WOxEInlLi0Rn09Spu8v8F79QmWdDSUm4Mevjj2HcOA29iOwlFXpbXH99WM3++9+HRYvCGLBkx1FHhd98Hnkk/KAUkTZToWfq2mvDZXajR4ezyZKS2InSc9FF8NWvhmkB1q9v/XgR2YMKvTXucPXVcN114eah+fNV5rnSoUOYjbG2Fs4/X0MvIm2kQm+JO1x1VbgK47zz4N57Vea51r9/mODs8cfhnntipxEpKCr05riHDz+nTg1ni/fco+Xk2sv48TB0aFi67vXXY6cRKRhqqKa4w5Qp8K//GiaQuvtulXl76tAh/DZkFn4zqquLnUikIKilGnMPK9RPnx7uXrzzTpV5DEccATNnwooVcNddsdOIFAQ1VUPu4df8W24JswDOnq0yj2nsWBg2LCzpV1kZO41I3lNb7eIe5mb5+c/D5XN33KGbhmIzC59d7LcfjBmjoReRVqjQIZT5RReFBSouvjjMb64yzw9lZeH/l2eeCX+KSLNU6HV1MGECzJoVhltmzlSZ55vRo+Gb3wxXHa1bFzuNSN4q7kKvqwtj5XfeGT4InTFDZZ6PzMKVRp07h5u7amtjJxLJS8Vb6HV14XrnOXPCJYo336wyz2eHHho+pH7uufChtYh8QnEWel1dmNXvnnvCr/HTpqnMC8HIkfDtb4e7d1evjp1GJO8UX6HX1obL4e69NxTDjTeqzAuFWbgm/VOfgh/8AHbujJ1IJK8UV6HX1oY7DxcuDLMnXn+9yrzQfPrTodRXrQrDZCLyv4qn0GtrwwdqixaFmROvuSZ2Itlb3/lOGH65/np4/vnYaUTyRnEUek1NuPTtvvvCEMvVV8dOJPtq1izo3j0MvezYETuNSF5Iv9BrauDcc8MCxNOmwZVXxk4k2dCjR7iU8fnnw4yYIpJ4oe/cCd/7HixeHMZbL788diLJphEjwg/rqVPDmLpIkUu30HfuDAs5L1kSbhiaNCl2IsmF226DXr3C0Mv27bHTiESVZqHv2BE+NHvooXAr/09+EjuR5Mohh8C8eeG69GuvjZ1GJKr0Cn3HDvjud2Hp0jDJ1iWXxE4kuTZ8eLi3YPp0+MMfYqcRiSatQt++Hf7hH+Dhh+H228Pq8VIcbrkF+vQJQy9btsROIxJFOoW+fXu4PnnZsjDnx4UXxk4k7alrV5g/P8zG2KMHfOUr4XOTZcvg3XdjpxNpF+buUV64vLzcKyoqsvNk27bB2WfD8uXhLsLx47PzvFJ4nnkGHnkEnn4aVq7cfY36wIHwd38HgweHP484QncJS0Eys1XuXt7kvoIv9G3b4Kyz4NFHw3XJ48bt+3NKGrZtC6X+zDOh4J99Fj78MOwrKwvFvqvkP/c5LTcoBSHdQv/4YzjzTHjiiTBz4tix2QknaaqtDVfDPP307pJ/662wr2tXOOWU3QVfXg4HHBA3r0gT0iz0rVvDjSVPPhlmThwzJnvhpDi4wxtv7Fnwa9aEfZ06waBBuwv+5JOhW7e4eUVIsdC3bg1Lkq1YAQsWhCsbRLJh06YwNLOr4FetCtNHmIVhmV1j8IMHh2EbkXbWUqFnNGhoZsPMbJ2ZVZrZlCb2m5ndXr//BTM7YV9DN9a7d/g3ZQZ2YBfsqScxr6P35OIs8z3ejwZfvXsrxz7l6Nkz/OY3Y0ZYHWnzZnjqqTBDZ+/eYbbOUaOgb1/o1y9MPXD33WEop64uL96PfMigHHFytHqGbmYlwJ+BrwNVwErgHHd/ucExZwAXAmcAXwZuc/cvt/S8bT1Db+mChEi/ZESVL+9H0eWoqQkTgj3zzO6z+LffDvu6d8fea/4SSV+7DkpKwoevHTrs/ntzfzbetqsBWlF0/58UWY6WztA7ZvD9g4BKd3+1/skWAyOAlxscMwJY5OGnw3Nm1s3MDnX3v2YeU6QAdOwIJ54YviZODP8SX3ll9zj8/Ba+95hj9v31dxV9Sz8IeKf57+/XL/zZXLu0ZXurx/6l+RxHHdX8vpaee6+OXdv8rmOPzfx19tmanL9CJoXeB1jf4HEV4Sy8tWP6AHsUupmNA8YBHH744W3NKpJ/zOCznw1fY8a0XOi//GVYz7a2ds8/M92W6b67WsgwZEjzp4Nt2Z7JsZUt5Chv8gSz5efe22PXtbDvuOMyf6191cLPlWzJpNCb+vHX+F3M5BjcfS4wF8KQSwavLZKOUaPa53VaKvSFC9snA8D9Le1raWeWPdjSvpZ2ZtmS3L9EJh+KVgF9GzwuAzbsxTEiIpJDmRT6SmCAmR1pZp2AkcCyRscsA0bXX+1yErA52+PnvXq1bXvq8uX9UI78y5EPGZQjTo5Wh1zcvcbMJgCPASXAfHdfbWbj6/fPAZYTrnCpBLYCWb/LZ+PGbD9jYcuX90M59pQPOfIhAyhHY+2RI5MxdNx9OaG0G26b0+DvDlyQ3WgiItIWmo1IRCQRKnQRkUSo0EVEEqFCFxFJRLTZFs2sGnhjL7+9J7Api3EKnd6PPen92E3vxZ5SeD+OcPfSpnZEK/R9YWYVzU1OU4z0fuxJ78duei/2lPr7oSEXEZFEqNBFRBJRqIU+N3aAPKP3Y096P3bTe7GnpN+PghxDFxGRTyrUM3QREWlEhS4ikoiCK/TWFqwuJmbW18xWmNkaM1ttZhNjZ4rNzErM7I9m9u+xs8RWvxTkQ2a2tv6/ka/EzhSLmV1S/2/kJTN7wMwOiJ0pFwqq0OsXrJ4NDAcGAueY2cC4qaKqAS5192OBk4ALivz9AJhIeyzeWBhuAx5192OAL1Ck74uZ9QEuAsrd/XOEacBHxk2VGwVV6DRYsNrddwC7FqwuSu7+V3f/n/q/byH8g+0TN1U8ZlYG/D0wL3aW2MzsU8BXgXsB3H2Hu38QN1VUHYHOZtYR6EKiK6oVWqE3txh10TOzfsAXgT/ETRLVrcAkoC52kDzQH6gGFtQPQc0zswNjh4rB3d8Cfga8SVi4frO7Px43VW4UWqFntBh1sTGzg4B/Ay529w9j54nBzP4v8I67r4qdJU90BE4A7nL3LwIfAUX5mZOZHUL4Tf5I4DDgQDP7ftxUuVFoha7FqBsxs/0IZf5Ld18aO09EpwDfMrPXCUNxp5nZfXEjRVUFVLn7rt/YHiIUfDH6GvCau1e7+05gKXBy5Ew5UWiFnsmC1UXDzIwwRrrG3WfGzhOTu1/u7mXu3o/w38VT7p7kWVgm3H0jsN7Mjq7fNBR4OWKkmN4ETjKzLvX/ZoaS6AfEGa0pmi+aW7A6cqyYTgHOBV40sz/Vb7uifg1YkQuBX9af/LxKDhZvLwTu/gczewj4H8KVYX8k0SkAdOu/iEgiCm3IRUREmqFCFxFJhApdRCQRKnQRkUSo0EVEEqFCFxFJhApdRCQR/x9irGb9TnEXNQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting single point\n",
    "plt.plot(pred[20,5,20,0,:], 'r', y_true[20,5,20,0,:], 'bs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pred_inverse=discretizer.inverse_transform(tf.reshape(pred, (-1,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(pred_inverse, bins=discretizer.bin_edges_[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another method to discretize.\n",
    "# import pandas as pd\n",
    "\n",
    "# z3=z.flatten()\n",
    "# z3.shape\n",
    "# bins2=pd.qcut(z3, 10, labels=False,retbins=True) \n",
    "# #quantiles based method. ensures almost equal items per bin\n",
    "# bins2\n",
    "# bins2[0].shape, bins2[1].shape #bins, bin-edges\n",
    "\n",
    "# from collections import Counter\n",
    "# recounted=Counter(bins2[0])\n",
    "# recounted\n",
    "\n",
    "# #this is useless. we had to do onehot encoding.\n",
    "\n",
    "#another method\n",
    "\n",
    "# z4=bins2[0]\n",
    "# z4.shape, type(z4)\n",
    "# values = z4\n",
    "# #print(values)\n",
    "# # integer encode\n",
    "# label_encoder = LabelEncoder()\n",
    "# integer_encoded = label_encoder.fit_transform(values)\n",
    "# #print(integer_encoded)\n",
    "# # binary encode\n",
    "# onehot_encoder = OneHotEncoder(sparse=False)\n",
    "# integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "# onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "# print(onehot_encoded)\n",
    "# # # invert first example\n",
    "# # inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "# # print(inverted)\n",
    "\n",
    "# values=z4\n",
    "# onehot_encoder = OneHotEncoder(sparse=False)\n",
    "# values = values.reshape(len(values), 1)\n",
    "# onehot_encoded = onehot_encoder.fit_transform(values)\n",
    "\n",
    "# print(values.shape, values[6000])\n",
    "# print('min:', values.min(), 'max:', values.max())\n",
    "\n",
    "# onehot_encoded.shape, onehot_encoded[6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATTEMPTING UNIFORM BINNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((992, 32, 64, 93), (992, 32, 64, 2))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.7825012, 2.6023862)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.min(), y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4. , -3.6, -3.2, -2.8, -2.4, -2. , -1.6, -1.2, -0.8, -0.4,  0. ,\n",
       "        0.4,  0.8,  1.2,  1.6,  2. ,  2.4,  2.8,  3.2,  3.6,  4. ])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins=np.linspace(-4, 4, 21)\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins[0]=-np.inf; bins[-1]=np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-inf, -3.6, -3.2, -2.8, -2.4, -2. , -1.6, -1.2, -0.8, -0.4,  0. ,\n",
       "        0.4,  0.8,  1.2,  1.6,  2. ,  2.4,  2.8,  3.2,  3.6,  inf])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4063232,)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.7, -3.7825012)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.max(), y.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1[0,0,0,0]=4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.7"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.cut(y1.reshape(-1), bins, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19,  6,  6, ...,  7,  7,  8])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4063232,)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 19)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.min(), a.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(992, 32, 64, 2)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=a.reshape(y.shape)\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.utils as np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=np_utils.to_categorical(d, num_classes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.max(), c.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(992, 32, 64, 2, 20)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0,0,0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.data_generator_categorical import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_categorical_loss(y_true, y_pred):\n",
    "    #assert tf.shape(y_true)==tf.shape(y_pred)\n",
    "    #assert tf.rank(y_true)==5 #[batch_size, lat, lon, 2, ]\n",
    "    #assert tf.shape(y_true)[3]==2 #len(args['outpt_vars'])\n",
    "    \n",
    "    cce=tf.keras.losses.CategoricalCrossentropy()\n",
    "    cce1=cce(y_true[:,:,:,0,:], y_pred[:,:,:,0,:])\n",
    "    cce2=cce(y_true[:,:,:,1,:], y_pred[:,:,:,1,:])\n",
    "    return (cce1+cce2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
